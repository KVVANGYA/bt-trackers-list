name: Update BT Trackers List

on:
  workflow_dispatch:
  schedule:
    - cron: '0 0 * * *' # 每天 UTC 时间 0 点运行
  push:
    branches:
      - main # 或你的默认分支名

jobs:
  update-list:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          persist-credentials: false

      - name: Create Merge Script
        run: |
          cat > merge_trackers.sh << 'EOF'
          #!/bin/bash
          
          TMP_DIR=$(mktemp -d)
          echo "Using temporary directory: $TMP_DIR"
          
          # 定义 Tracker 列表 URLs
          urls=(
            "https://raw.githubusercontent.com/ngosang/trackerslist/master/trackers_all.txt"
            "https://raw.githubusercontent.com/ngosang/trackerslist/master/trackers_all_ip.txt"
            "https://raw.githubusercontent.com/ngosang/trackerslist/master/trackers_all_udp.txt"
            "https://raw.githubusercontent.com/ngosang/trackerslist/master/trackers_all_http.txt"
            "https://raw.githubusercontent.com/ngosang/trackerslist/master/trackers_all_https.txt"
            "https://raw.githubusercontent.com/ngosang/trackerslist/master/trackers_best.txt"
            "https://raw.githubusercontent.com/ngosang/trackerslist/master/trackers_best_ip.txt"
            
            "https://cf.trackerslist.com/all.txt"
            "https://cf.trackerslist.com/best.txt"
            "https://cf.trackerslist.com/http.txt"
            "https://cf.trackerslist.com/udp.txt"
            
            "https://raw.githubusercontent.com/XIU2/TrackersListCollection/master/all.txt"
            "https://raw.githubusercontent.com/XIU2/TrackersListCollection/master/best.txt"
            "https://raw.githubusercontent.com/XIU2/TrackersListCollection/master/http.txt"
            # "https://raw.githubusercontent.com/XIU2/TrackersListCollection/master/udp.txt" # 注释掉已知有问题的源
            
            "https://newtrackon.com/api/all"
            "https://newtrackon.com/api/stable?include_ipv4_only_trackers=1&include_ipv6_only_trackers=1"
            
            # "https://trackers.mlsub.net/all.txt" # 注释掉已知有问题的源
            
            "https://raw.githubusercontent.com/DeSireFire/animeTrackerList/master/AT_all.txt"
            
            "https://torrends.to/torrent-tracker-list/?download=latest"
            
            "https://raw.githubusercontent.com/hezhijie0327/Trackerslist/refs/heads/main/trackerslist_combine.txt"
            "https://raw.githubusercontent.com/Tunglies/TrackersList/refs/heads/main/all.txt"
            "https://raw.githubusercontent.com/adysec/tracker/main/trackers_all.txt"
            
            "https://cdn.jsdelivr.net/gh/ngosang/trackerslist@master/trackers_all.txt"
            "https://cdn.jsdelivr.net/gh/XIU2/TrackersListCollection@master/all.txt"
          )
          
          RAW_MERGED_FILE="$TMP_DIR/trackers_raw_merged.txt"      # 完全原始合并文件
          SPLIT_FILE="$TMP_DIR/trackers_split.txt"               # 分割后的文件
          FILTERED_FILE="$TMP_DIR/trackers_filtered.txt"         # 过滤后的文件
          FINAL_FILE="trackers_final.txt"
          
          # 清空或创建临时输出文件
          > "$RAW_MERGED_FILE"
          
          # 遍历 URL 并获取内容
          for url in "${urls[@]}"; do
            echo "Fetching $url..."
            # 使用 curl 获取内容，静默模式，失败时显示错误
            # --max-time 30 设置最大请求时间，避免卡住
            # -H "User-Agent: Mozilla/5.0" 添加 User-Agent 头部
            content=$(curl -sSL --fail --max-time 30 -H "User-Agent: Mozilla/5.0" "$url" 2>/dev/null)
            
            # 检查 curl 是否成功
            if [ $? -eq 0 ] && [ -n "$content" ]; then
              # 将内容追加到临时输出文件
              echo "$content" >> "$RAW_MERGED_FILE"
              # 添加一个换行符以确保列表项分隔
              echo "" >> "$RAW_MERGED_FILE"
            else
              echo "Warning: Failed to fetch or empty content from $url"
            fi
          done
          
          # === 新增步骤：分割粘连的 URLs ===
          # 使用 grep 和 sed 来识别并分割常见的 Tracker 协议模式
          cat "$RAW_MERGED_FILE" | \
            sed 's/https:\/\//\nhttps:\/\//g' | \
            sed 's/http:\/\//\nhttp:\/\//g' | \
            sed 's/udp:\/\//\nudp:\/\//g' | \
            sed 's/ws:\/\//\nws:\/\//g' | \
            sed 's/wss:\/\//\nwss:\/\//g' | \
            grep -v '^[[:space:]]*$' > "$SPLIT_FILE"
          
          # 初始化过滤后的文件
          > "$FILTERED_FILE"
          
          # 逐行处理分割后的文件
          while IFS= read -r line || [[ -n "$line" ]]; do # 处理最后一行可能没有换行符的情况
            # 使用 sed 去除行首行尾空白字符
            trimmed_line=$(echo "$line" | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')
            
            # 跳过空行和注释行
            if [ -n "$trimmed_line" ] && [ "${trimmed_line#\#}" = "$trimmed_line" ]; then # 不以 # 开头且非空
              # 定义一个函数来检查是否为有效的 Tracker URL
              # 检查是否以常见的 tracker 协议开头
              case "$trimmed_line" in
                http://*|https://*|udp://*|ws://*|wss://*)
                  # 进一步检查：确保协议后有内容 (避免 http:// 这样的无效 URL)
                  # 提取协议后的部分
                  rest="${trimmed_line#*://}"
                  if [ -n "$rest" ]; then
                    # 基本的有效性检查通过，写入文件
                    echo "$trimmed_line" >> "$FILTERED_FILE"
                  fi
                  ;;
                *)
                  # 特殊处理 newtrackon.com API 返回的纯域名:端口格式 (匹配 api/all 或 api/stable)
                  # 检查当前处理的 URL 是否来自 newtrackon (这是一个简化检查，实际在循环外无法精确知道)
                  # 但我们可以在处理时检查行的格式
                  if echo "$trimmed_line" | grep -qE '^[a-zA-Z0-9.\-]+:[0-9]+(/announce)?$'; then
                     # 为 newtrackon 的格式添加 udp:// 前缀
                     # 确保不重复添加 /announce
                     if echo "$trimmed_line" | grep -q '/announce$'; then
                        echo "udp://$trimmed_line" >> "$FILTERED_FILE"
                     else
                        echo "udp://$trimmed_line/announce" >> "$FILTERED_FILE"
                     fi
                  else
                     # 可选：打印被过滤掉的行用于调试 (生产环境建议注释掉)
                     # echo "DEBUG - Filtered out: '$trimmed_line'"
                     :
                  fi
                  ;;
              esac
            fi
          done < "$SPLIT_FILE"
          
          # 智能去重函数：标准化 URL 并去重
          python3 - <<PY_EOF > "$TMP_DIR/deduplicated.txt" 2>"$TMP_DIR/python_error.log"
          from urllib.parse import urlparse
          import sys
          import re
          
          def normalize_url(url):
              """标准化 URL，移除默认端口"""
              try:
                  # 预处理：移除 URL 末尾可能的多余字符（如 HTML 标签）
                  # 匹配直到第一个空白字符、引号、尖括号或行尾
                  match = re.match(r'^([a-zA-Z][a-zA-Z0-9+.-]*://[^\s"\'<>]+)', url)
                  if match:
                      clean_url = match.group(1)
                  else:
                      clean_url = url
                      
                  parsed = urlparse(clean_url)
                  scheme = parsed.scheme.lower()
                  netloc = parsed.netloc.lower()
                  path = parsed.path
                  params = parsed.params
                  query = parsed.query
                  fragment = parsed.fragment
                  
                  # 移除默认端口
                  if ':' in netloc:
                      # 分离主机名和端口部分
                      if ']' in netloc: # IPv6 地址 [::1]:8080
                          if netloc.endswith(']'): # 没有端口
                              pass
                          elif netloc.rfind(':') > netloc.rfind(']'): # 有端口
                              host_part = netloc[:netloc.rfind(':')]
                              port_part = netloc[netloc.rfind(':')+1:]
                              if port_part.isdigit():
                                  port_num = int(port_part)
                                  # 移除默认端口
                                  if (scheme == 'http' and port_num == 80) or \
                                     (scheme == 'https' and port_num == 443) or \
                                     (scheme == 'ws' and port_num == 80) or \
                                     (scheme == 'wss' and port_num == 443):
                                      netloc = host_part
                      else: # IPv4 或域名
                          if ':' in netloc and not netloc.startswith('['):
                              host, port = netloc.rsplit(':', 1)
                              if port.isdigit():
                                  port_num = int(port)
                                  # 移除默认端口
                                  if (scheme == 'http' and port_num == 80) or \
                                     (scheme == 'https' and port_num == 443) or \
                                     (scheme == 'ws' and port_num == 80) or \
                                     (scheme == 'wss' and port_num == 443):
                                      netloc = host
                  
                  # 重建 URL
                  normalized = f"{scheme}://{netloc}{path}"
                  if params:
                      normalized += f";{params}"
                  if query:
                      normalized += f"?{query}"
                  if fragment:
                      normalized += f"#{fragment}"
                      
                  return normalized
              except Exception as e:
                  # 如果解析失败，返回原始 URL (清理后的)
                  print(f"Warning: Failed to parse URL '{url}': {e}", file=sys.stderr)
                  return url
          
          # 读取过滤后的 URLs
          try:
              with open('$FILTERED_FILE', 'r') as f:
                  urls = [line.strip() for line in f if line.strip()]
          except FileNotFoundError:
              print(f"Error: File '$FILTERED_FILE' not found.", file=sys.stderr)
              sys.exit(1)
          except Exception as e:
              print(f"Error reading file '$FILTERED_FILE': {e}", file=sys.stderr)
              sys.exit(1)
          
          # 标准化并去重
          normalized_urls = {}
          for url in urls:
              try:
                  normalized = normalize_url(url)
                  # 保留第一个出现的 URL（原始格式）
                  if normalized not in normalized_urls:
                      normalized_urls[normalized] = url
              except Exception as e:
                  print(f"Warning: Failed to process URL '{url}': {e}", file=sys.stderr)
                  # 即使处理单个 URL 出错，也继续处理其他 URL
                  continue
          
          # 输出去重后的 URLs
          for original_url in sorted(normalized_urls.values()):
              print(original_url)
          
          PY_EOF
          
          # 检查 Python 脚本是否有错误
          if [ -f "$TMP_DIR/python_error.log" ] && [ -s "$TMP_DIR/python_error.log" ]; then
              echo "=== Python Script Errors ==="
              cat "$TMP_DIR/python_error.log"
              echo "============================"
          fi
          
          # 将去重后的结果复制到最终文件
          if [ -f "$TMP_DIR/deduplicated.txt" ]; then
              cp "$TMP_DIR/deduplicated.txt" "$FINAL_FILE"
          else
              echo "Error: Deduplication failed, output file not created."
              exit 1
          fi
          
          # 创建带时间戳的文件（可选）
          TIMESTAMP=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
          cp "$FINAL_FILE" "trackers_$TIMESTAMP.txt"
          
          # 清理临时目录
          rm -rf "$TMP_DIR"
          
          echo "Merge, deduplication, and filtering complete."
          echo "Final file: $FINAL_FILE"
          echo "Total trackers: $(wc -l < $FINAL_FILE)"
          EOF
          
          chmod +x merge_trackers.sh

      - name: Run Merge Script
        run: ./merge_trackers.sh

      - name: Configure Git
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'

      - name: Commit and Push Changes
        run: |
          git add trackers_final.txt
          # 可选：添加带时间戳的文件
          # git add trackers_*.txt
          
          if ! git diff --cached --quiet; then
            git commit -m "Update trackers list ($(date -u))"
            git push https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git HEAD:main
          else
            echo "No changes to commit."
          fi
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
